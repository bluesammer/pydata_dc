{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fuzzy Search \n",
    "\n",
    "## PyData DC 2016\n",
    "\n",
    "Jiaqi Liu\n",
    "\n",
    "https://github.com/jiaqi216/pydata_dc\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**whoami**\n",
    "\n",
    "- Jiaqi Liu\n",
    "- Data Scientist @ Capital One\n",
    "- NYC based\n",
    "- work mostly at the intersection of data science and engineering\n",
    "- https://github.com/jiaqi216/pydata_dc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Fuzzy Match Algorithms**\n",
    "\n",
    "- Soundex \n",
    "- Levenshtein\n",
    "- n-gram (model?)\n",
    "- NLTK/Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Soundex**\n",
    "\n",
    "- phonetic algorithm\n",
    "- index by sound as pronounced in English\n",
    "- assigns a soundex coding \n",
    "- ideal for spelling inconsistencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**American Soundex Coding**\n",
    "\n",
    "[http://www.archives.gov/research/census/soundex.html](http://www.archives.gov/research/census/soundex.html)\n",
    "\n",
    "every soundex code is a letter and three numbers\n",
    "\n",
    "| Number | Letter |\n",
    "|---------|----------|\n",
    "|1|B,F,P,V|\n",
    "|2|C,G,J,K,Q,S,X,Z|\n",
    "|3|D,T|\n",
    "|4|L|\n",
    "|5|M,N|\n",
    "|6|R|\n",
    "\n",
    "Ignore A,E,I,O,U,H,W,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W252\n",
      "W252\n"
     ]
    }
   ],
   "source": [
    "import jellyfish as j\n",
    "\n",
    "a=j.soundex('WASHINGTON')\n",
    "print(a)\n",
    "b=j.soundex('WUSHINGTON')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L200\n",
      "L263\n"
     ]
    }
   ],
   "source": [
    "a=j.soundex('LGA')\n",
    "print(a)\n",
    "b=j.soundex('LAGUARDIA')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S120\n",
      "S120\n"
     ]
    }
   ],
   "source": [
    "a=j.soundex('SBUX#123')\n",
    "print(a)\n",
    "a2=j.soundex('SBUX')\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Soundex**\n",
    "- Soundex is pretty easy to implement\n",
    "- Computationally fast\n",
    "- only works on ASCII characters (no foreign languages)\n",
    "- How do you calculate distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Levenshtein distance**\n",
    "- also call edit distance\n",
    "- accounts for how many characters you have to change to have the same string\n",
    "- computationally fast (can handle real time processing)\n",
    "- pairwise comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Levenshtein as l\n",
    "\n",
    "l.distance('SMYTHE', 'SMITH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.distance('SBUX', 'Starbucks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S120\n",
      "S361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=j.soundex('SBUX#123')\n",
    "print(a)\n",
    "b=j.soundex('Starbucks')\n",
    "print(b)\n",
    "\n",
    "l.distance(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pitfall: Comparing Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str99 = '99 Broadway'\n",
    "str100 = '100 Broadway'\n",
    "str999 = '999 Broadway'\n",
    "\n",
    "l.distance(str99, str100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- weighing numbers differently from letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.distance('caf√©', 'cafe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.distance('cafe', 'cafe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Longer Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str1='Hello world, python is great'\n",
    "str2='Hello world, python is good'\n",
    "l.distance(str1,str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Levenshtein as l\n",
    "str1='great'\n",
    "str2='good'\n",
    "l.distance(str1,str2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- counting raw edits penalizes long strings: use a ratio of edits to length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Damerau-Levenshtein**\n",
    "- like Levenshtein but accounts for transposition of adjacent characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.damerau_levenshtein_distance('recieve', 'receive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.levenshtein_distance('recieve', 'receive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "def load_cities_list():\n",
    "    cities = []\n",
    "    with open('data/misspelled_cities.csv') as data_file:\n",
    "        reader = csv.reader(data_file, delimiter='|')\n",
    "        for correct, wrong in reader:\n",
    "            cities.append({'correct': correct,'wrong': wrong})\n",
    "    return cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "4\n",
      "11\n",
      "1\n",
      "2\n",
      "12\n",
      "2\n",
      "1\n",
      "5\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for city in load_cities_list():\n",
    "    print(j.levenshtein_distance(city['correct'], city['wrong']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**n-gram/Trigram**\n",
    "\n",
    "- groupings of letters (takes into more context)\n",
    "- proper unit of analysis (1-gram, 2-gram, 3-gram)\n",
    "- slower to implement - need to calculate n-gram for each string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ngram(tokens, n):\n",
    "    grams =[tokens[i:i+n] for i in range(len(tokens)-(n-1))]\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'quick', 'brown']\n",
      "['quick', 'brown', 'fox']\n",
      "['brown', 'fox', 'jumped']\n",
      "['fox', 'jumped', 'over']\n",
      "['jumped', 'over', 'a']\n",
      "['over', 'a', 'lazy']\n",
      "['a', 'lazy', 'dog']\n"
     ]
    }
   ],
   "source": [
    "sentence_gram = \"The quick brown fox jumped over a lazy dog\".split()\n",
    "grams = ngram(sentence_gram, 3)\n",
    "\n",
    "for gram in grams:\n",
    "    print(gram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ngram(tokens, n):\n",
    "    grams =[tokens[i:i+n] for i in range(len(tokens)-(n-1))]\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sta\n",
      "tar\n",
      "arb\n",
      "rbu\n",
      "buc\n",
      "uck\n",
      "cks\n"
     ]
    }
   ],
   "source": [
    "word_gram = \"Starbucks\"\n",
    "grams = ngram(word_gram, 3)\n",
    "\n",
    "for gram in grams:\n",
    "    print(gram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scoring Similarity: Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sim(a_tri,b_tri):\n",
    "    intersect = len(set(a_tri) & set(b_tri))\n",
    "    union = len(set(a_tri) | set(b_tri))\n",
    "    return float(intersect)/(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sta', 'tar', 'arb', 'rbu', 'buc', 'uck', 'cks']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(grams)\n",
    "get_sim(grams, grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Word2Vec: uses cosine distance\n",
    "cosine distance between two vectors is nice but like have to find a way to quantify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_gram = ngram('Starbux', 3)\n",
    "get_sim(grams, new_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4666666666666667"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_gram = ngram('RichmondConventionCtner', 3)\n",
    "b_gram = ngram('Richmond Convention Center', 3)\n",
    "get_sim(a_gram, b_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_gram = ngram('receved data', 3)\n",
    "b_gram = ngram('received date', 3)\n",
    "get_sim(a_gram, b_gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Trigam Search with Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('postgresql://hhu373@localhost/cities')\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#https://www.postgresql.org/docs/9.1/static/pgtrgm.html\n",
    "query=\"\"\"\n",
    "    SELECT \n",
    "                a.alt_spelling, \n",
    "                similarity(lower(a.alt_spelling), :city) as similarity \n",
    "    FROM        fuzzy_names as a \n",
    "    WHERE       lower(a.alt_spelling) % :city\n",
    "    ORDER BY    similarity DESC\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sqlalchemy.sql import text\n",
    "\n",
    "city_name = 'washington'\n",
    "res = engine.execute(text(query), city=city_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' Washington D.C.', 0.733333),\n",
       " (' Washinton DC', 0.5),\n",
       " (' WSHINGTON DC', 0.5),\n",
       " (' WSHINGTONDC', 0.4375)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Other Similarity Metrics**\n",
    "- NLTK: wordnet\n",
    "- Word2Vec: uses cosine distance\n",
    "    - cosine distance between two vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word1 = wordnet.synsets(\"blue\")\n",
    "word2 = wordnet.synsets(\"green\")\n",
    "word1[0].wup_similarity(word2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
